# coding=gbk
import json
import re
from urllib import request
import requests
import urllib3
from bs4 import BeautifulSoup
import scrapy
from scrapy import Request
from xiangqingye.items import XiangqingyeItem
from urllib.request import urlopen
import urllib

class doubanSpider(scrapy.Spider):
    name = "a"
    allowed_domains = ["douban.com"]

    def start_requests(self):
        for i in range(20,300):
            url1 = 'https://movie.douban.com/j/new_search_subjects?sort=U&range=0,10&tags=%E7%94%B5%E8%A7%86%E5%89%A7&start='+str(i)+'&countries=%E9%9F%A9%E5%9B%BD'

            yield Request(url1,headers={'User-Agent': "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1",
                         })
            i+=20

    def parse(self, response):
        a=json.loads(response.text)
        tvs =a['data']
        tv_list=[]
        for i in range(0, len(tvs)):
            item=XiangqingyeItem()
            item['rate'] = tvs[i]['rate']
            item['cover'] = tvs[i]['cover'].replace('\\','')
            item['url'] = tvs[i]['url'].replace('\\','')
            item['tv_name'] = tvs[i]['title']
            item['director']=tvs[i]['directors']
            item['actor']=tvs[i]['casts']
            tv_list.append(item)

            yield scrapy.Request(item["url"], callback=self.parse_detail, meta={"item": item},
                                 headers={
                                     'User-Agent': "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36"})  # °ÑÈ¡µ½µÄÊý¾ÝÌá½»¸øpipline´¦Àí

    def parse_detail(self, response):
        item = response.meta["item"]
        fff=requests.get(item['url'])
        html=BeautifulSoup(fff.text,'html.parser')
        #item['showtime'] = info[8].split(':')[-1].strip()
        #item['length'] = info[9].split(':')[-1].strip()
        description = html.find_all("span", attrs={"property": "v:summary"})[0].get_text()
        item['abstract'] = description.lstrip().lstrip('\n\t').rstrip().rstrip('\n\t').replace('\n', '\t')

        yield item


